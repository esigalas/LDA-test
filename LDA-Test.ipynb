{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06defbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "plt.style.use('classic')\n",
    "%matplotlib inline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e760f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ce2a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.__version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "858161f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d24baa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cross_temporal_decoding(data_array, title='Cross Temporal Decoding', xylines=[]):\n",
    "    plt.figure(figsize=(6, 6), dpi=60)\n",
    "    plt.imshow(data_array, origin='lower', vmin=0, vmax=1)\n",
    "    for xyline in xylines:\n",
    "        plt.axvline(x=xyline, color='white')\n",
    "        plt.axhline(y=xyline, color='white')\n",
    "    plt.title(title)\n",
    "    plt.colorbar(shrink=0.75)\n",
    "    plt.xlabel(\"Test set time window\")\n",
    "    plt.ylabel(\"Train set time window\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc72f247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(dataset, dataset_labels, train_size=None, test_size=None, features=None):\n",
    "    \"\"\"\n",
    "        Split the given dataset to train and test. Also selecting a specific set of features if given in the input argument.\n",
    "    \"\"\"\n",
    "    split_dataset = {}\n",
    "    if features is None:\n",
    "        features = np.arange(dataset.shape[2])\n",
    "    if train_size is None:\n",
    "        train_size = int(dataset.shape[0]*2/3)\n",
    "    if test_size is None:\n",
    "        test_size = int(dataset.shape[0]*1/3)\n",
    "\n",
    "    trial_indices = np.arange(dataset.shape[0])\n",
    "    np.random.shuffle(trial_indices)\n",
    "    dataset = dataset[trial_indices,:,:]\n",
    "    dataset_labels = dataset_labels[trial_indices]\n",
    "\n",
    "    split_dataset['train'] = dataset[:train_size, :, features]\n",
    "    split_dataset['test'] = dataset[-test_size:, :, features]\n",
    "    split_dataset['train_labels'] = dataset_labels[:train_size]\n",
    "    split_dataset['test_labels'] = dataset_labels[-test_size:]\n",
    "    \n",
    "    return split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19c30824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_performance_LDA(train_set, train_labels, test_set, test_labels, solver_method=None):\n",
    "    \"\"\"\n",
    "        Perform LDA by fitting on the train set and measure the accuracy on the test set.\n",
    "    \"\"\"\n",
    "    if solver_method is None:\n",
    "        solver_method='svd'\n",
    "    clf = LinearDiscriminantAnalysis(solver=solver_method)   \n",
    "    clf.fit(train_set, train_labels)\n",
    "    score = clf.score(test_set, test_labels)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70499085",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_bin = 5\n",
    "bin_step = 1\n",
    "T = 75 # The trial length.\n",
    "perf_matrix_range = np.arange(0, T-bin_step, bin_step)\n",
    "perf_matrix_length = len(perf_matrix_range)\n",
    "\n",
    "# just some plot parameters\n",
    "time_points = [int(T*(1/15)), int(T*(3/15)), int(T*(7/15)), int(T*(9/15)),  int(T*(13/15))]\n",
    "xy = []\n",
    "for time_point in time_points:\n",
    "     xy.append(np.where(perf_matrix_range==time_point)[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ad365b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Features 50\n",
      "Trained Trials 50\n",
      "Tested Trials 50\n",
      "Data version 0\n",
      "Train set shape: (50, 75, 50)\n",
      "Test set shape: (50, 75, 50)\n",
      "Data version 1\n",
      "Train set shape: (50, 75, 50)\n",
      "Test set shape: (50, 75, 50)\n",
      "Data version 2\n",
      "Train set shape: (50, 75, 50)\n",
      "Test set shape: (50, 75, 50)\n",
      "Random Features 50\n",
      "Trained Trials 100\n",
      "Tested Trials 50\n",
      "Data version 0\n",
      "Train set shape: (100, 75, 50)\n",
      "Test set shape: (50, 75, 50)\n",
      "Data version 1\n",
      "Train set shape: (100, 75, 50)\n",
      "Test set shape: (50, 75, 50)\n",
      "Data version 2\n",
      "Train set shape: (100, 75, 50)\n",
      "Test set shape: (50, 75, 50)\n",
      "Random Features 50\n",
      "Trained Trials 150\n",
      "Tested Trials 50\n",
      "Data version 0\n",
      "Train set shape: (150, 75, 50)\n",
      "Test set shape: (50, 75, 50)\n",
      "Data version 1\n",
      "Train set shape: (150, 75, 50)\n",
      "Test set shape: (50, 75, 50)\n",
      "Data version 2\n",
      "Train set shape: (150, 75, 50)\n",
      "Test set shape: (50, 75, 50)\n",
      "Random Features 50\n",
      "Trained Trials 200\n",
      "Tested Trials 50\n",
      "Data version 0\n",
      "Train set shape: (200, 75, 50)\n",
      "Test set shape: (50, 75, 50)\n",
      "Data version 1\n",
      "Train set shape: (200, 75, 50)\n",
      "Test set shape: (50, 75, 50)\n",
      "Data version 2\n",
      "Train set shape: (200, 75, 50)\n",
      "Test set shape: (50, 75, 50)\n",
      "Random Features 50\n",
      "Trained Trials 250\n",
      "Tested Trials 50\n",
      "Data version 0\n",
      "Train set shape: (250, 75, 50)\n",
      "Test set shape: (50, 75, 50)\n",
      "Data version 1\n",
      "Train set shape: (250, 75, 50)\n",
      "Test set shape: (50, 75, 50)\n",
      "Data version 2\n",
      "Train set shape: (250, 75, 50)\n",
      "Test set shape: (50, 75, 50)\n",
      "Random Features 50\n",
      "Trained Trials 300\n",
      "Tested Trials 50\n",
      "Data version 0\n",
      "Train set shape: (300, 75, 50)\n",
      "Test set shape: (50, 75, 50)\n",
      "Data version 1\n",
      "Train set shape: (300, 75, 50)\n",
      "Test set shape: (50, 75, 50)\n",
      "Data version 2\n",
      "Train set shape: (300, 75, 50)\n",
      "Test set shape: (50, 75, 50)\n",
      "Random Features 50\n",
      "Trained Trials 350\n",
      "Tested Trials 50\n",
      "Data version 0\n",
      "Train set shape: (350, 75, 50)\n",
      "Test set shape: (50, 75, 50)\n",
      "Data version 1\n",
      "Train set shape: (350, 75, 50)\n",
      "Test set shape: (50, 75, 50)\n",
      "Data version 2\n",
      "Train set shape: (350, 75, 50)\n",
      "Test set shape: (50, 75, 50)\n",
      "Random Features 100\n",
      "Trained Trials 50\n",
      "Tested Trials 50\n",
      "Data version 0\n",
      "Train set shape: (50, 75, 100)\n",
      "Test set shape: (50, 75, 100)\n",
      "Data version 1\n",
      "Train set shape: (50, 75, 100)\n",
      "Test set shape: (50, 75, 100)\n",
      "Data version 2\n",
      "Train set shape: (50, 75, 100)\n",
      "Test set shape: (50, 75, 100)\n",
      "Random Features 100\n",
      "Trained Trials 100\n",
      "Tested Trials 50\n",
      "Data version 0\n",
      "Train set shape: (100, 75, 100)\n",
      "Test set shape: (50, 75, 100)\n",
      "Data version 1\n",
      "Train set shape: (100, 75, 100)\n",
      "Test set shape: (50, 75, 100)\n",
      "Data version 2\n",
      "Train set shape: (100, 75, 100)\n",
      "Test set shape: (50, 75, 100)\n",
      "Random Features 100\n",
      "Trained Trials 150\n",
      "Tested Trials 50\n",
      "Data version 0\n",
      "Train set shape: (150, 75, 100)\n",
      "Test set shape: (50, 75, 100)\n",
      "Data version 1\n",
      "Train set shape: (150, 75, 100)\n",
      "Test set shape: (50, 75, 100)\n",
      "Data version 2\n",
      "Train set shape: (150, 75, 100)\n",
      "Test set shape: (50, 75, 100)\n",
      "Random Features 100\n",
      "Trained Trials 200\n",
      "Tested Trials 50\n",
      "Data version 0\n",
      "Train set shape: (200, 75, 100)\n",
      "Test set shape: (50, 75, 100)\n",
      "Data version 1\n",
      "Train set shape: (200, 75, 100)\n",
      "Test set shape: (50, 75, 100)\n",
      "Data version 2\n",
      "Train set shape: (200, 75, 100)\n",
      "Test set shape: (50, 75, 100)\n",
      "Random Features 100\n",
      "Trained Trials 250\n",
      "Tested Trials 50\n",
      "Data version 0\n",
      "Train set shape: (250, 75, 100)\n",
      "Test set shape: (50, 75, 100)\n",
      "Data version 1\n",
      "Train set shape: (250, 75, 100)\n",
      "Test set shape: (50, 75, 100)\n",
      "Data version 2\n",
      "Train set shape: (250, 75, 100)\n",
      "Test set shape: (50, 75, 100)\n",
      "Random Features 100\n",
      "Trained Trials 300\n",
      "Tested Trials 50\n",
      "Data version 0\n",
      "Train set shape: (300, 75, 100)\n",
      "Test set shape: (50, 75, 100)\n",
      "Data version 1\n",
      "Train set shape: (300, 75, 100)\n",
      "Test set shape: (50, 75, 100)\n",
      "Data version 2\n",
      "Train set shape: (300, 75, 100)\n",
      "Test set shape: (50, 75, 100)\n",
      "Random Features 100\n",
      "Trained Trials 350\n",
      "Tested Trials 50\n",
      "Data version 0\n",
      "Train set shape: (350, 75, 100)\n",
      "Test set shape: (50, 75, 100)\n",
      "Data version 1\n",
      "Train set shape: (350, 75, 100)\n",
      "Test set shape: (50, 75, 100)\n",
      "Data version 2\n",
      "Train set shape: (350, 75, 100)\n",
      "Test set shape: (50, 75, 100)\n",
      "Random Features 150\n",
      "Trained Trials 50\n",
      "Tested Trials 50\n",
      "Data version 0\n",
      "Train set shape: (50, 75, 150)\n",
      "Test set shape: (50, 75, 150)\n",
      "Data version 1\n",
      "Train set shape: (50, 75, 150)\n",
      "Test set shape: (50, 75, 150)\n",
      "Data version 2\n",
      "Train set shape: (50, 75, 150)\n",
      "Test set shape: (50, 75, 150)\n",
      "Random Features 150\n",
      "Trained Trials 100\n",
      "Tested Trials 50\n",
      "Data version 0\n",
      "Train set shape: (100, 75, 150)\n",
      "Test set shape: (50, 75, 150)\n",
      "Data version 1\n",
      "Train set shape: (100, 75, 150)\n",
      "Test set shape: (50, 75, 150)\n",
      "Data version 2\n",
      "Train set shape: (100, 75, 150)\n",
      "Test set shape: (50, 75, 150)\n",
      "Random Features 150\n",
      "Trained Trials 150\n",
      "Tested Trials 50\n",
      "Data version 0\n",
      "Train set shape: (150, 75, 150)\n",
      "Test set shape: (50, 75, 150)\n",
      "Data version 1\n",
      "Train set shape: (150, 75, 150)\n",
      "Test set shape: (50, 75, 150)\n",
      "Data version 2\n",
      "Train set shape: (150, 75, 150)\n",
      "Test set shape: (50, 75, 150)\n",
      "Random Features 150\n",
      "Trained Trials 200\n",
      "Tested Trials 50\n",
      "Data version 0\n",
      "Train set shape: (200, 75, 150)\n",
      "Test set shape: (50, 75, 150)\n",
      "Data version 1\n",
      "Train set shape: (200, 75, 150)\n",
      "Test set shape: (50, 75, 150)\n",
      "Data version 2\n",
      "Train set shape: (200, 75, 150)\n",
      "Test set shape: (50, 75, 150)\n",
      "Random Features 150\n",
      "Trained Trials 250\n",
      "Tested Trials 50\n",
      "Data version 0\n",
      "Train set shape: (250, 75, 150)\n",
      "Test set shape: (50, 75, 150)\n",
      "Data version 1\n",
      "Train set shape: (250, 75, 150)\n",
      "Test set shape: (50, 75, 150)\n",
      "Data version 2\n",
      "Train set shape: (250, 75, 150)\n",
      "Test set shape: (50, 75, 150)\n",
      "Random Features 150\n",
      "Trained Trials 300\n",
      "Tested Trials 50\n",
      "Data version 0\n",
      "Train set shape: (300, 75, 150)\n",
      "Test set shape: (50, 75, 150)\n"
     ]
    }
   ],
   "source": [
    "for solver in ['svd']:\n",
    "    for random_picks in [50,100,150,200,250,300,350]:\n",
    "        for train_trials in [50,100,150,200,250,300,350]:\n",
    "            # set the size of the test trials\n",
    "            test_trials=50\n",
    "            print('Random Features '+str(random_picks) +'\\nTrained Trials '+str(train_trials) +'\\nTested Trials '+str(test_trials))\n",
    "            # set the matrix with the performance matrices of lda for all versions of data\n",
    "            all_performances_matrices_lda = []\n",
    "            for version in np.arange(3):\n",
    "                print(\"Data version\",version)\n",
    "                # matrix that keeps the lda scores of all train set time windows to the respective test set time windows\n",
    "                performance_matrix_lda = np.zeros((perf_matrix_length, perf_matrix_length))\n",
    "                # Load datasets and their respective labels: shape(trials X time X features)\n",
    "                data = np.load('trial_data_'+str(version)+\".npy\")\n",
    "                data_labels = np.load('trial_labels_'+str(version)+'.npy')\n",
    "                # pick random features\n",
    "                random_features = np.random.choice(data.shape[2], random_picks, replace=False)\n",
    "                # create dataset with train and test sets from random features\n",
    "                dataset = split_train_test(data, data_labels, features=random_features, train_size=train_trials, test_size=test_trials)\n",
    "\n",
    "                print(\"Train set shape:\", dataset['train'].shape)\n",
    "                print(\"Test set shape:\", dataset['test'].shape)\n",
    "                # iterate over train time bin trials\n",
    "                for a, j in enumerate(perf_matrix_range):\n",
    "                    #print(i, i+time_bin)\n",
    "                    train_set = np.mean(dataset['train'][:,j:j+time_bin,:], axis=1)\n",
    "                    # iterate over test time bin trials\n",
    "                    for b, k in enumerate(perf_matrix_range):\n",
    "                        #print(k, k+time_bin)\n",
    "                        test_set = np.mean(dataset['test'][:,k:k+time_bin,:], axis=1)\n",
    "                        # compute the LDA score of the train set on the test set and add it in the respective position in the performance matrix\n",
    "                        performance_matrix_lda[a,b] = compute_performance_LDA(train_set, dataset['train_labels'],\n",
    "                                                                              test_set, dataset['test_labels'],\n",
    "                                                                              solver_method=solver)\n",
    "                # add this version scores in the list with all the matrices\n",
    "                all_performances_matrices_lda.append(performance_matrix_lda)\n",
    "            # plot an iamge of the mean performances of all 3 data versions\n",
    "            plot_cross_temporal_decoding(np.mean(all_performances_matrices_lda, axis=0), str(random_picks)+' Random Picked Features\\n'+str(train_trials)+' Trained Trials\\n'+str(test_trials)+' Tested Trials\\n',\n",
    "                                                     xylines=xy)\n",
    "            plt.savefig(solver+'_train-size'+str(train_trials)+'_random-features'+str(random_picks)+'_test-size'+str(test_trials)+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f7ab575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 75, 400)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be208acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5d879d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
